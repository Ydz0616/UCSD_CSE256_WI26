Loading data and creating tokenizer ...
Vocabulary size is 5755
Total number of parameters in the Encoder: 569664
Epoch 1/15 - Loss: 1.0972 - Train acc: 44.65% | Test acc: 33.33%
Epoch 2/15 - Loss: 1.0443 - Train acc: 52.68% | Test acc: 44.67%
Epoch 3/15 - Loss: 0.7396 - Train acc: 64.91% | Test acc: 56.67%
Epoch 4/15 - Loss: 1.4550 - Train acc: 70.46% | Test acc: 66.13%
Epoch 5/15 - Loss: 0.6164 - Train acc: 78.49% | Test acc: 69.87%
Epoch 6/15 - Loss: 0.5811 - Train acc: 80.26% | Test acc: 68.80%
Epoch 7/15 - Loss: 0.6249 - Train acc: 90.20% | Test acc: 79.73%
Epoch 8/15 - Loss: 0.2613 - Train acc: 93.50% | Test acc: 80.40%
Epoch 9/15 - Loss: 0.0788 - Train acc: 93.31% | Test acc: 81.47%
Epoch 10/15 - Loss: 0.4672 - Train acc: 95.08% | Test acc: 81.33%
Epoch 11/15 - Loss: 0.3029 - Train acc: 96.51% | Test acc: 84.27%
Epoch 12/15 - Loss: 0.0411 - Train acc: 97.28% | Test acc: 84.40%
Epoch 13/15 - Loss: 0.0073 - Train acc: 95.84% | Test acc: 82.67%
Epoch 14/15 - Loss: 0.0524 - Train acc: 98.80% | Test acc: 84.93%
Epoch 15/15 - Loss: 0.0173 - Train acc: 98.95% | Test acc: 84.93%


